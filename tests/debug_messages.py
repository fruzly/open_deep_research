"""
è°ƒè¯•å·¥å…·ï¼šåˆ†ææ¶ˆæ¯æ ¼å¼å’Œå†…å®¹
"""

import asyncio
import uuid
import os
import traceback
from src.open_deep_research.multi_agent import supervisor_builder
from langgraph.checkpoint.memory import MemorySaver

def analyze_message(msg, context=""):
    """åˆ†æå•ä¸ªæ¶ˆæ¯çš„æ ¼å¼å’Œå†…å®¹"""
    print(f"\n=== æ¶ˆæ¯åˆ†æ {context} ===")
    print(f"ç±»å‹: {type(msg)}")
    print(f"å†…å®¹: {msg}")
    
    if isinstance(msg, dict):
        print("âœ… å­—å…¸æ ¼å¼æ¶ˆæ¯")
        print(f"  - è§’è‰²: {msg.get('role', 'N/A')}")
        print(f"  - å†…å®¹: {msg.get('content', 'N/A')}")
        if 'tool_calls' in msg:
            print(f"  - å·¥å…·è°ƒç”¨: {msg['tool_calls']}")
    elif hasattr(msg, 'type'):
        # LangChain æ¶ˆæ¯å¯¹è±¡
        msg_type = msg.type if hasattr(msg, 'type') else type(msg).__name__.lower()
        print(f"âœ… LangChainæ¶ˆæ¯å¯¹è±¡ ({msg_type})")
        
        # æ ¹æ®ç±»å‹æ¨æ–­è§’è‰²
        if 'human' in msg_type or 'user' in msg_type:
            role = 'user'
        elif 'ai' in msg_type or 'assistant' in msg_type:
            role = 'assistant'
        elif 'system' in msg_type:
            role = 'system'
        elif 'tool' in msg_type:
            role = 'tool'
        else:
            role = getattr(msg, 'role', 'unknown')
            
        print(f"  - è§’è‰²: {role}")
        print(f"  - å†…å®¹: {getattr(msg, 'content', 'N/A')}")
        
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            print(f"  - å·¥å…·è°ƒç”¨: {msg.tool_calls}")
        if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs:
            print(f"  - é™„åŠ å‚æ•°: {msg.additional_kwargs}")
    elif hasattr(msg, 'role') and hasattr(msg, 'content'):
        print("âœ… LangChainæ¶ˆæ¯å¯¹è±¡")
        print(f"  - è§’è‰²: {msg.role}")
        print(f"  - å†…å®¹: {msg.content}")
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            print(f"  - å·¥å…·è°ƒç”¨: {msg.tool_calls}")
    else:
        print("âŒ æœªçŸ¥æ¶ˆæ¯æ ¼å¼")
        print(f"  - å±æ€§: {[attr for attr in dir(msg) if not attr.startswith('_')]}")

def analyze_message_list(messages, context=""):
    """åˆ†ææ¶ˆæ¯åˆ—è¡¨"""
    print(f"\nğŸ” åˆ†ææ¶ˆæ¯åˆ—è¡¨ {context}")
    print(f"æ¶ˆæ¯æ•°é‡: {len(messages)}")
    
    for i, msg in enumerate(messages):
        analyze_message(msg, f"[{i}]")
    
    print("\nğŸ“Š æ¶ˆæ¯åºåˆ—æ‘˜è¦:")
    roles = []
    for msg in messages:
        if isinstance(msg, dict):
            roles.append(msg.get('role', 'unknown'))
        elif hasattr(msg, 'type'):
            # LangChain æ¶ˆæ¯å¯¹è±¡
            msg_type = msg.type if hasattr(msg, 'type') else type(msg).__name__.lower()
            if 'human' in msg_type or 'user' in msg_type:
                roles.append('user')
            elif 'ai' in msg_type or 'assistant' in msg_type:
                roles.append('assistant')
            elif 'system' in msg_type:
                roles.append('system')
            elif 'tool' in msg_type:
                roles.append('tool')
            else:
                roles.append(getattr(msg, 'role', 'unknown'))
        elif hasattr(msg, 'role'):
            roles.append(msg.role)
        else:
            roles.append('unknown')
    
    print(f"è§’è‰²åºåˆ—: {' -> '.join(roles)}")
    
    # æ£€æŸ¥Geminiè¦æ±‚
    if roles:
        last_role = roles[-1]
        if last_role == 'user':
            print("âœ… æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼ˆç¬¦åˆGeminiè¦æ±‚ï¼‰") 
        else:
            print(f"âš ï¸ æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ {last_role}ï¼ˆå¯èƒ½ä¸ç¬¦åˆGeminiè¦æ±‚ï¼‰")

async def debug_multi_agent():
    """è¯¦ç»†è°ƒè¯•multi_agentåŠŸèƒ½"""
    print("ğŸ” å¼€å§‹è¯¦ç»†è°ƒè¯•multi_agent...")
    
    try:
        # åˆ›å»ºagent
        checkpointer = MemorySaver()
        agent = supervisor_builder.compile(name="debug_research_team", checkpointer=checkpointer)
        
        # é…ç½® - ä½¿ç”¨æ›´ç®€å•çš„è®¾ç½®
        config = {
            "thread_id": str(uuid.uuid4()),
            "search_api": "none",  # ç¦ç”¨æœç´¢APIä»¥ç®€åŒ–æ¶ˆæ¯æµ
            "supervisor_model": "google_genai:gemini-2.5-flash-lite-preview-06-17",
            "researcher_model": "google_genai:gemini-2.5-flash-lite-preview-06-17",
            "number_of_queries": 10,  # å‡å°‘æŸ¥è¯¢æ•°é‡
        }
        
        thread_config = {"configurable": config, "recursion_limit": 20}  # é™ä½é€’å½’é™åˆ¶
        
        # æµ‹è¯•æ¶ˆæ¯ - ä½¿ç”¨æ›´ç®€å•çš„é—®é¢˜
        test_msg = [{"role": "user", "content": "Focus on Anthropicâ€‘backed open standard for integrating external context and tools with LLMs, give an architectural overview for developers, tell me about interesting MCP servers, compare to google Agent2Agent (A2A) protocol. write the report and dont ask any follow up questions"}]
        
        print(f"ğŸ“ è¾“å…¥æ¶ˆæ¯: {test_msg}")
        print(f"âš™ï¸ é…ç½®: {config}")
        
        # åˆ†æåˆå§‹æ¶ˆæ¯åºåˆ—
        analyze_message_list(test_msg, "åˆå§‹è¾“å…¥")
        
        # è®¾ç½®è°ƒè¯•ç¯å¢ƒå˜é‡
        os.environ["DEBUG_MULTI_AGENT"] = "true"
        
        print("ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        response = await agent.ainvoke({"messages": test_msg}, config=thread_config)
        print("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“„ å“åº”: {response}")
        
        
        print("="*40)
        for m in agent.get_state(thread_config).values['messages']:
            m.pretty_print()
        print("="*40)
        
        # è·å–çŠ¶æ€å¹¶æ˜¾ç¤ºæ‰€æœ‰æ¶ˆæ¯
        state = agent.get_state(thread_config)
        if hasattr(state, 'values') and 'messages' in state.values:
            print("\nğŸ“‹ å®Œæ•´æ¶ˆæ¯å†å²:")
            for i, m in enumerate(state.values['messages']):
                print(f"\n--- æ¶ˆæ¯ {i} ---")
                if hasattr(m, 'pretty_print'):
                    m.pretty_print()
                else:
                    print(f"æ¶ˆæ¯å†…å®¹: {m}")
            
            # åˆ†ææœ€ç»ˆæ¶ˆæ¯åºåˆ—
            analyze_message_list(state.values['messages'], "æœ€ç»ˆçŠ¶æ€")
        
        print("="*40)
        from IPython.display import Markdown
        
        # å®‰å…¨åœ°æ£€æŸ¥ final_report æ˜¯å¦å­˜åœ¨
        state_values = agent.get_state(thread_config).values
        if 'final_report' in state_values and state_values['final_report']:
            print("ğŸ“„ æœ€ç»ˆæŠ¥å‘Š:")
            print(state_values['final_report'])
        else:
            print("â„¹ï¸  å½“å‰æµ‹è¯•åœºæ™¯æ²¡æœ‰ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºä½¿ç”¨äº†ç®€åŒ–é…ç½®ï¼‰")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        
        # æ‰“å°å®Œæ•´çš„traceback
        print("\nğŸ”´ å®Œæ•´é”™è¯¯è¿½è¸ª:")
        traceback.print_exc()
        
        # å¦‚æœæ˜¯ KeyErrorï¼Œæ‰“å°æ›´å¤šè°ƒè¯•ä¿¡æ¯
        if isinstance(e, KeyError):
            print(f"\nğŸ”‘ KeyError è¯¦ç»†ä¿¡æ¯:")
            print(f"ç¼ºå°‘çš„é”®: {e.args}")
            
        # å¦‚æœæ˜¯ ChatGoogleGenerativeAIErrorï¼Œæä¾›ä¿®å¤å»ºè®®
        if "ChatGoogleGenerativeAIError" in str(type(e)):
            print(f"\nğŸ’¡ Gemini é”™è¯¯ä¿®å¤å»ºè®®:")
            print("1. æ£€æŸ¥æ¶ˆæ¯åºåˆ—æ˜¯å¦ç¬¦åˆ Gemini è¦æ±‚")
            print("2. ç¡®ä¿ function call ç´§è·Ÿåœ¨ user turn æˆ– function response ä¹‹å")
            print("3. æ£€æŸ¥æ˜¯å¦æœ‰è¿ç»­çš„ assistant æ¶ˆæ¯")
            
        return False

if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_keys = ["GOOGLE_API_KEY"]
    missing_keys = [key for key in required_keys if not os.environ.get(key)]
    
    if missing_keys:
        print(f"âš ï¸ ç¼ºå°‘ç¯å¢ƒå˜é‡: {missing_keys}")
        print("è¯·è®¾ç½®æ‰€éœ€çš„APIå¯†é’¥")
    else:
        # è¿è¡Œè°ƒè¯•
        result = asyncio.run(debug_multi_agent())
        if result:
            print("ğŸ‰ è°ƒè¯•æˆåŠŸï¼")
        else:
            print("ğŸ’¥ è°ƒè¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥") 


"""
# è¿è¡Œå‘½ä»¤
G:\MyProjects\open_deep_research> python .\debug_messages.py
# è¾“å‡ºç»“æœ

ğŸ” å¼€å§‹è¯¦ç»†è°ƒè¯•multi_agent...
ğŸ“ è¾“å…¥æ¶ˆæ¯: [{'role': 'user', 'content': 'Write a simple overview of Python programming language.'}]  
âš™ï¸ é…ç½®: {'thread_id': '0663a8b7-b278-49e7-b371-358bd6851c3f', 'search_api': 'none', 'supervisor_model'
: 'google_genai:gemini-2.5-flash-lite-preview-06-17', 'researcher_model': 'google_genai:gemini-2.5-flash-lite-preview-06-17', 'number_of_queries': 1}

ğŸ” åˆ†ææ¶ˆæ¯åˆ—è¡¨ åˆå§‹è¾“å…¥
æ¶ˆæ¯æ•°é‡: 1

=== æ¶ˆæ¯åˆ†æ [0] ===
ç±»å‹: <class 'dict'>
å†…å®¹: {'role': 'user', 'content': 'Write a simple overview of Python programming language.'}
âœ… å­—å…¸æ ¼å¼æ¶ˆæ¯
- è§’è‰²: user
- å†…å®¹: Write a simple overview of Python programming language.

ğŸ“Š æ¶ˆæ¯åºåˆ—æ‘˜è¦:
è§’è‰²åºåˆ—: user
âœ… æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼ˆç¬¦åˆGeminiè¦æ±‚ï¼‰
ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...
âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼
ğŸ“„ å“åº”: {'messages': [HumanMessage(content='Write a simple overview of Python programming language.', 
additional_kwargs={}, response_metadata={}, id='7e7c9692-cc54-460c-986d-b8132a643843'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'FinishReport', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite-preview-06-17', 'safety_ratings': []}, id='run--c5be8b9d-359c-4714-b7d7-d4c13bbbf21e-0', tool_calls=[{'name': 'FinishReport', 'args': {}, 'id': 'afde1fe5-96d7-4c4f-b1a4-bae32570b78b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1013, 'output_tokens': 9, 'total_tokens': 1022, 'input_token_details': {'cache_read': 0}})], 'source_str': ''}

ğŸ“‹ å®Œæ•´æ¶ˆæ¯å†å²:

--- æ¶ˆæ¯ 0 ---
================================ Human Message =================================

Write a simple overview of Python programming language.

--- æ¶ˆæ¯ 1 ---
================================== Ai Message ==================================
Tool Calls:
FinishReport (afde1fe5-96d7-4c4f-b1a4-bae32570b78b)
Call ID: afde1fe5-96d7-4c4f-b1a4-bae32570b78b
Args:

ğŸ” åˆ†ææ¶ˆæ¯åˆ—è¡¨ æœ€ç»ˆçŠ¶æ€
æ¶ˆæ¯æ•°é‡: 2

=== æ¶ˆæ¯åˆ†æ [0] ===
ç±»å‹: <class 'langchain_core.messages.human.HumanMessage'>
å†…å®¹: content='Write a simple overview of Python programming language.' additional_kwargs={} response_metadata={} id='7e7c9692-cc54-460c-986d-b8132a643843'
âœ… LangChainæ¶ˆæ¯å¯¹è±¡ (human)
- è§’è‰²: user
- å†…å®¹: Write a simple overview of Python programming language.

=== æ¶ˆæ¯åˆ†æ [1] ===
ç±»å‹: <class 'langchain_core.messages.ai.AIMessage'>
å†…å®¹: content='' additional_kwargs={'function_call': {'name': 'FinishReport', 'arguments': '{}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite-preview-06-17', 'safety_ratings': []} id='run--c5be8b9d-359c-4714-b7d7-d4c13bbbf21e-0' tool_calls=[{'name': 'FinishReport', 'args': {}, 'id': 'afde1fe5-96d7-4c4f-b1a4-bae32570b78b', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1013, 'output_tokens': 9, 'total_tokens': 1022, 'input_token_details': {'cache_read': 0}}
âœ… LangChainæ¶ˆæ¯å¯¹è±¡ (ai)
- è§’è‰²: assistant
- å†…å®¹:
- å·¥å…·è°ƒç”¨: [{'name': 'FinishReport', 'args': {}, 'id': 'afde1fe5-96d7-4c4f-b1a4-bae32570b78b', 'type': 'tool_call'}]
- é™„åŠ å‚æ•°: {'function_call': {'name': 'FinishReport', 'arguments': '{}'}}

ğŸ“Š æ¶ˆæ¯åºåˆ—æ‘˜è¦:
è§’è‰²åºåˆ—: user -> assistant
âš ï¸ æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ assistantï¼ˆå¯èƒ½ä¸ç¬¦åˆGeminiè¦æ±‚ï¼‰
ğŸ‰ è°ƒè¯•æˆåŠŸï¼    

"""